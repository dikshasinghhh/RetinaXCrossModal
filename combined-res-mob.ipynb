{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1836058,"sourceType":"datasetVersion","datasetId":1091489},{"sourceId":2822650,"sourceType":"datasetVersion","datasetId":1715304},{"sourceId":3521043,"sourceType":"datasetVersion","datasetId":2118574}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, ConcatDataset, Subset\nfrom torchvision import datasets, models\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Configuration\ntrain_csv_path = '/kaggle/input/aptos2019/train_1.csv'\nval_csv_path = '/kaggle/input/aptos2019/test.csv'\ntrain_images_path = '/kaggle/input/aptos2019/train_images/train_images'\nval_images_path = '/kaggle/input/aptos2019/test_images/test_images'\nadditional_dataset_1 = '/kaggle/input/diabetic-retinopathy-resized-arranged'\nadditional_dataset_2 = '/kaggle/input/diabetic-retinopathy-dataset'\nnum_classes = 5\n\n# Class distribution constraints\nclass_limits = {\n    0: 1000,  # Healthy (No DR)\n    1: 370,   # Mild DR\n    2: 900,   # Moderate DR\n    3: 190,   # Severe DR\n    4: 290    # Proliferative DR\n}\n\ndef get_data_loaders():\n    class DRDataset(Dataset):\n        def __init__(self, csv_file, root_dir, transform=None):\n            self.df = pd.read_csv(csv_file)\n            self.root_dir = root_dir\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.df)\n\n        def __getitem__(self, idx):\n            img_id = self.df.iloc[idx]['id_code']\n            img_path = os.path.join(self.root_dir, f'{img_id}.png')\n            image = Image.open(img_path).convert('RGB')\n            label = int(self.df.iloc[idx]['diagnosis'])\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n\n    train_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        transforms.ToTensor()\n    ])\n    val_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    train_dataset_csv = DRDataset(train_csv_path, train_images_path, train_transform)\n    train_dataset_1 = datasets.ImageFolder(root=additional_dataset_1, transform=train_transform)\n    train_dataset_2 = datasets.ImageFolder(root=additional_dataset_2, transform=train_transform)\n    val_dataset = DRDataset(val_csv_path, val_images_path, val_transform)\n\n    # Filtering dataset based on class limits\n    def filter_dataset(dataset):\n        class_counts = {k: 0 for k in class_limits.keys()}\n        indices = []\n        for idx in range(len(dataset)):\n            _, label = dataset[idx]\n            if class_counts[label] < class_limits[label]:\n                indices.append(idx)\n                class_counts[label] += 1\n        return Subset(dataset, indices)\n    \n    train_dataset_csv = filter_dataset(train_dataset_csv)\n    train_dataset_1 = filter_dataset(train_dataset_1)\n    train_dataset_2 = filter_dataset(train_dataset_2)\n    \n    train_dataset = ConcatDataset([train_dataset_csv, train_dataset_1, train_dataset_2])\n\n    labels = [sample[1] for sample in train_dataset]\n    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n    class_weights = torch.tensor(class_weights, dtype=torch.float)\n\n    weights = [class_weights[label] for label in labels]\n    sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n\n    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n    return train_loader, val_loader, class_weights\n\ntrain_loader, val_loader, class_weights = get_data_loaders()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Model Selection\ndef get_model(model_name):\n    if model_name == \"resnet\":\n        model = models.resnet50(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif model_name == \"mobilenet\":\n        model = models.mobilenet_v2(pretrained=True)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    else:\n        raise ValueError(\"Model not supported\")\n    return model.to(device)\n\n# Training & Evaluation Functions\ndef train_one_epoch(model, dataloader, criterion, optimizer):\n    model.train()\n    running_loss = 0.0\n    all_preds, all_labels = [], []\n    for images, labels in tqdm(dataloader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        preds = torch.argmax(outputs, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    return running_loss / len(dataloader), f1_score(all_labels, all_preds, average='weighted')\n\ndef evaluate(model, dataloader, criterion):\n    model.eval()\n    running_loss = 0.0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            preds = torch.argmax(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    return running_loss / len(dataloader), f1_score(all_labels, all_preds, average='weighted')\n\n# Training Loop\ndef train_model(model_name):\n    model = get_model(model_name)\n    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n    \n    best_val_loss = float('inf')\n    early_stop_counter = 0\n    early_stop_patience = 20\n    \n    for epoch in range(1, 21):\n        print(f\"\\nEpoch {epoch}/20 - {model_name}\")\n        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer)\n        val_loss, val_f1 = evaluate(model, val_loader, criterion)\n        print(f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n        scheduler.step(val_loss)\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), f\"best_{model_name}_model.pth\")\n            print(\"âœ… Saved new best model.\")\n        else:\n            early_stop_counter += 1\n        \n        if early_stop_counter >= early_stop_patience:\n            print(\"ðŸ”¥ Early stopping triggered.\")\n            break\n    print(f\"ðŸŽ‰ Training Complete for {model_name}.\")\n\n# Train both models\ntrain_model(\"resnet\")\ntrain_model(\"mobilenet\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T09:11:31.395106Z","iopub.execute_input":"2025-03-13T09:11:31.395330Z","execution_failed":"2025-03-13T09:28:03.027Z"}},"outputs":[],"execution_count":null}]}